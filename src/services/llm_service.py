import json
from typing import Any, Dict

import ollama

from config.settings import settings


class LLMParsingService:
    """Servi√ßo para parsear transcri√ß√µes usando LLM local (Ollama)"""

    def __init__(self, model: str, host: str):
        self.model = model
        self.host = host
        print(f"ü§ñ LLM Service inicializado: {model}")

    def parse_workout(self, transcription: str) -> Dict[str, Any]:
        """Parse uma transcri√ß√£o de treino usando LLM
        
        Args:
            transcription: Texto transcrito do √°udio
            
        Returns:
            Dict com dados estruturados do treino

        """
        prompt = self._build_prompt(transcription)

        print(f"ü§ñ Enviando para LLM ({self.model})...")

        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": prompt,
                }],
            )

            content = response["message"]["content"]

            # Limpar markdown se presente
            content = content.replace("```json", "").replace("```", "").strip()

            # Parsear JSON
            parsed_data = json.loads(content)

            print("‚úÖ LLM parseou com sucesso!")
            return parsed_data

        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao parsear JSON do LLM: {e}")
            print(f"Resposta do LLM: {content[:200]}...")
            return {}
        except Exception as e:
            print(f"‚ùå Erro no LLM: {e}")
            return {}

    def _build_prompt(self, transcription: str) -> str:
        """Constr√≥i o prompt para o LLM"""
        return f"""Voc√™ √© um assistente especializado em fitness. Extraia informa√ß√µes estruturadas do seguinte relato de treino em portugu√™s:

"{transcription}"

IMPORTANTE: Retorne APENAS um JSON v√°lido (sem markdown, sem explica√ß√µes, sem texto adicional).

Formato esperado:
{{
  "body_weight_kg": float ou null,
  "energy_level": int de 1-10 ou null,
  "start_time": "HH:MM" ou null,
  "end_time": "HH:MM" ou null,
  "resistance_exercises": [
    {{
      "name": "nome do exerc√≠cio em min√∫sculas",
      "sets": n√∫mero de s√©ries,
      "reps": [repeti√ß√µes por s√©rie],
      "weight_kg": carga em kg,
      "notes": "observa√ß√µes ou null"
    }}
  ],
  "aerobic_exercises": [
    {{
      "name": "nome do exerc√≠cio em min√∫sculas",
      "duration_minutes": dura√ß√£o em minutos,
      "distance_km": dist√¢ncia em km ou null,
      "intensity_level": "low" ou "moderate" ou "high" ou "hiit",
      "notes": "observa√ß√µes ou null"
    }}
  ],
  "notes": "observa√ß√µes gerais ou null"
}}

Regras:
- Se um campo n√£o foi mencionado, use null
- Nomes de exerc√≠cios em min√∫sculas: "supino", "agachamento", "corrida"
- Se ouvir "3x12", significa 3 s√©ries de 12 repeti√ß√µes: {{"sets": 3, "reps": [12, 12, 12]}}
- Se ouvir "3 s√©ries de 12, 10 e 8", use: {{"sets": 3, "reps": [12, 10, 8]}}
- N√£o invente dados que n√£o foram mencionados
- Retorne APENAS o JSON, sem texto antes ou depois"""

# Inst√¢ncia global
_llm_service = None

def get_llm_service() -> LLMParsingService:
    """Retorna inst√¢ncia √∫nica do servi√ßo de LLM"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMParsingService(
            model=settings.LLM_MODEL,
            host=settings.OLLAMA_HOST,
        )
    return _llm_service
